{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from src.utils.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config, local_config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used to run: cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../yolov7/\")\n",
    "from utils.datasets import letterbox\n",
    "from utils.general import non_max_suppression_kpt\n",
    "from utils.plots import output_to_keypoint, plot_skeleton_kpts\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device used to run: {device}\")\n",
    "weigths = torch.load(\n",
    "    \"yolov7-w6-pose.pt\"\n",
    ")\n",
    "model = weigths['model']\n",
    "model = model.half().to(device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "1088\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../smear-beta/\")\n",
    "video_path = local_config['PATH']['raw_videos']+\"pose_estimation_1.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if (cap.isOpened() == False):\n",
    "    print('Video could not be read')\n",
    " \n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "\n",
    "scale_by = (\n",
    "    frame_width if frame_width > frame_height\n",
    "    else frame_height\n",
    ")\n",
    "scale_factor = 1\n",
    " \n",
    "# Pass the first frame through `letterbox` function to get the resized image,\n",
    "# to be used for `VideoWriter` dimensions. Resize by larger side.\n",
    "vid_write_image = letterbox(cap.read()[1], int(scale_by/scale_factor), stride=64, auto=True)[0]\n",
    "resize_height, resize_width = vid_write_image.shape[:2]\n",
    "\n",
    "print(resize_height)\n",
    "print(resize_width)\n",
    " \n",
    "save_name = local_config['PATH']['output_videos']+\"yolov7_vidal_test.mp4\"\n",
    "\n",
    "# Define codec and create VideoWriter object .\n",
    "out = cv2.VideoWriter(\n",
    "    save_name,\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'), \n",
    "    30,\n",
    "    (resize_width, resize_height)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(cap.isOpened):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "  \n",
    "    if ret:\n",
    "        orig_image = frame\n",
    "        image = cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB)\n",
    "        image = letterbox(image, int(scale_by/scale_factor), stride=64, auto=True)[0]\n",
    "        image_ = image.copy()\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = torch.tensor(np.array([image.numpy()]))\n",
    "        image = image.to(device)\n",
    "        image = image.half()\n",
    "    \n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(image)\n",
    "    \n",
    "        output = non_max_suppression_kpt(output, 0.25, 0.65, nc=model.yaml['nc'], nkpt=model.yaml['nkpt'], kpt_label=True)\n",
    "        output = output_to_keypoint(output)\n",
    "        nimg = image[0].permute(1, 2, 0) * 255\n",
    "        nimg = nimg.cpu().numpy().astype(np.uint8)\n",
    "        nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
    "        for idx in range(output.shape[0]):\n",
    "            plot_skeleton_kpts(nimg, output[idx, 7:].T, 3)\n",
    "    \n",
    "            # Comment/Uncomment the following lines to show bounding boxes around persons.\n",
    "            # xmin, ymin = (output[idx, 2]-output[idx, 4]/2), (output[idx, 3]-output[idx, 5]/2)\n",
    "            # xmax, ymax = (output[idx, 2]+output[idx, 4]/2), (output[idx, 3]+output[idx, 5]/2)\n",
    "            # cv2.rectangle(\n",
    "            #     nimg,\n",
    "            #     (int(xmin), int(ymin)),\n",
    "            #     (int(xmax), int(ymax)),\n",
    "            #     color=(255, 0, 0),\n",
    "            #     thickness=1,\n",
    "            #     lineType=cv2.LINE_AA\n",
    "            # )\n",
    "    \n",
    "        # Write the FPS on the current frame.\n",
    "        # cv2.putText(nimg, f\"{fps:.3f} FPS\", (15, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        #             1, (0, 255, 0), 2)\n",
    "        # Convert from BGR to RGB color format.\n",
    "        # cv2.imshow('image', nimg)\n",
    "        out.write(nimg)\n",
    "        # Press `q` to exit.\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        # No more frames to read\n",
    "        break\n",
    "  \n",
    "\n",
    "# Release VideoCapture().\n",
    "cap.release()\n",
    "out.release()\n",
    "# Close all frames and video windows.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
