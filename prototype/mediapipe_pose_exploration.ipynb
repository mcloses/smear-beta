{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "from src.utils.config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, local_config = load_config()\n",
    "\n",
    "test_filename = \"vidal_test.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(\n",
    "    local_config[\"PATH\"][\"raw_videos\"]+test_filename\n",
    ")\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "\n",
    "out = cv2.VideoWriter(\n",
    "    local_config[\"PATH\"][\"raw_videos\"]+\"vidal_test_prediction.avi\",\n",
    "    cv2.VideoWriter_fourcc('M','J','P','G'),\n",
    "    24,\n",
    "    (frame_width,frame_height)\n",
    ")\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "BG_COLOR = (192, 192, 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_pose.Pose(\n",
    "    static_image_mode=True,\n",
    "    model_complexity=2,\n",
    "    enable_segmentation=True,\n",
    "    min_detection_confidence=0.5\n",
    ") as pose:\n",
    "    \n",
    "    while (cap.isOpened()):\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            \n",
    "            frame_result = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            annotated_frame = frame.copy()\n",
    "            \n",
    "            # Draw pose landmarks on the image.\n",
    "            mp_drawing.draw_landmarks(\n",
    "                annotated_frame,\n",
    "                frame_result.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "        else: break\n",
    "            \n",
    "            \n",
    "cap.release()\n",
    "out.release()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "95e56559a4e59bc2ba69c80cafa85d9a61dcaf8b70837cc652e6338f3cb263ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
